Usage: protocol_inference.py [OPTIONS]

Options:
  --load_model TEXT            directory to pretrained/tuned model directory. [required]
  --max_seq_len INTEGER        Max input sequence length during training. The length should be <= n_hvg+1.
                               Default=same length as loaded model definition
  --config TEXT                Use config file. If using custom config file, input the path to the file directly.
                               Options=[pp, train, eval, Any<Path>]
  --freeze_predecoder BOOLEAN  Freeze pre-decoder. Default=False
  --batch_size INTEGER         Batch size during evaluation. Default=32
  --wandb_sync BOOLEAN         Enable WandB cloud syncing. Default=False
  --wandb_project TEXT         Project name in WandB. Recommend to use different project name other than training project.  [required]
  --wandb_name TEXT            Run name in WandB. Default=EMPTY.
  --help                       Show this message and exit.